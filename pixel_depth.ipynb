{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2 as cv\n",
    "import numpy\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "label =['person',\n",
    "'bicycle',\n",
    "'car',\n",
    "'motorcycle',\n",
    "'airplane',\n",
    "'bus',\n",
    "'train',\n",
    "'truck',\n",
    "'boat',\n",
    "'traffic light',\n",
    "'fire hydrant',\n",
    "'street sign',\n",
    "'stop sign',\n",
    "'parking meter',\n",
    "'bench',\n",
    "'bird',\n",
    "'cat',\n",
    "'dog',\n",
    "'horse',\n",
    "'sheep',\n",
    "'cow',\n",
    "'elephant',\n",
    "'bear',\n",
    "'zebra',\n",
    "'giraffe',\n",
    "'hat',\n",
    "'backpack',\n",
    "'umbrella',\n",
    "'shoe',\n",
    "'eye glasses',\n",
    "'handbag',\n",
    "'tie',\n",
    "'suitcase',\n",
    "'frisbee',\n",
    "'skis',\n",
    "'snowboard',\n",
    "'sports ball',\n",
    "'kite',\n",
    "'baseball bat',\n",
    "'baseball glove',\n",
    "'skateboard',\n",
    "'surfboard',\n",
    "'tennis racket',\n",
    "'bottle',\n",
    "'plate',\n",
    "'wine glass',\n",
    "'cup',\n",
    "'fork',\n",
    "'knife',\n",
    "'spoon',\n",
    "'bowl',\n",
    "'banana',\n",
    "'apple',\n",
    "'sandwich',\n",
    "'orange',\n",
    "'broccoli',\n",
    "'carrot',\n",
    "'hot dog',\n",
    "'pizza',\n",
    "'donut',\n",
    "'cake',\n",
    "'chair',\n",
    "'couch',\n",
    "'potted plant',\n",
    "'bed',\n",
    "'mirror',\n",
    "'dining table',\n",
    "'window',\n",
    "'desk',\n",
    "'toilet',\n",
    "'door',\n",
    "'tv',\n",
    "'laptop',\n",
    "'mouse',\n",
    "'remote',\n",
    "'keyboard',\n",
    "'cell phone',\n",
    "'microwave',\n",
    "'oven',\n",
    "'toaster',\n",
    "'sink',\n",
    "'refrigerator',\n",
    "'blender',\n",
    "'book',\n",
    "'clock',\n",
    "'vase',\n",
    "'scissors',\n",
    "'teddy bear',\n",
    "'hair drier',\n",
    "'toothbrush',\n",
    "'hair brush',]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "def get_points(x1, y1, x2, y2):\n",
    "\n",
    "    for x in range(x1, x2, 50):\n",
    "        for y in range(y1, y2, 50):\n",
    "            points.append((x, y))\n",
    "                  \n",
    "    return points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_depth(points):\n",
    "    final_depth = []\n",
    "    left  = cv.imread(\"D:\\\\Backpack-perfect\\\\Backpack-perfect\\\\im0.png\", cv.IMREAD_GRAYSCALE)\n",
    "    right = cv.imread(\"D:\\\\Backpack-perfect\\\\Backpack-perfect\\\\im1.png\", cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "    fx = 479.489        # lense focal length\n",
    "    baseline = 171.548  # distance in mm between the two cameras\n",
    "    disparities = 512 # num of disparities to consider\n",
    "    block = 31        # block size to match\n",
    "    units = 0.512     # depth units, adjusted for the output to fit in one byte\n",
    "\n",
    "    sbm = cv.StereoBM_create(numDisparities=disparities,\n",
    "                              blockSize=block)\n",
    "\n",
    "    # disparities\n",
    "    disparity = sbm.compute(left, right)\n",
    "    valid_pixels = disparity > 0\n",
    "\n",
    "\n",
    "    depth = numpy.zeros(shape=left.shape).astype(\"uint8\")\n",
    "    depth[valid_pixels] = (fx * baseline) / (units * disparity[valid_pixels])\n",
    "    for (x,y) in points:\n",
    "\n",
    "        if((x<valid_pixels.shape[0]) and (y<valid_pixels.shape[1]) and (valid_pixels[x][y])):\n",
    "            final_depth.append(depth[x][y])\n",
    "\n",
    "\n",
    "\n",
    "    depth = cv.equalizeHist(depth)\n",
    "    colorized_depth = numpy.zeros((left.shape[0], left.shape[1], 3), dtype=\"uint8\")\n",
    "    temp = cv.applyColorMap(depth, cv.COLORMAP_JET)\n",
    "    colorized_depth[valid_pixels] = temp[valid_pixels]\n",
    "    cv.imwrite(\"p.jpg\",colorized_depth)\n",
    "    (unique, counts) = numpy.unique(final_depth, return_counts=True)\n",
    "    frequencies = numpy.asarray((unique, counts)).T\n",
    "    return frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backpack\n",
      "[[47  3]\n",
      " [48  3]\n",
      " [49  6]\n",
      " [50  1]\n",
      " [51  6]\n",
      " [52 37]\n",
      " [53 36]\n",
      " [54 37]\n",
      " [55 26]\n",
      " [56 34]\n",
      " [57 23]\n",
      " [58 28]\n",
      " [59 11]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.gfile.FastGFile('frozen_inference_graph.pb', 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.graph.as_default()\n",
    "    tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "    img = cv.imread('D:\\\\Backpack-perfect\\\\Backpack-perfect\\\\im0.png')\n",
    "    rows = img.shape[0]\n",
    "    cols = img.shape[1]\n",
    "    inp = cv.resize(img, (300, 300))\n",
    "    inp = inp[:, :, [2, 1, 0]]  \n",
    "\n",
    "    out = sess.run([sess.graph.get_tensor_by_name('num_detections:0'),\n",
    "                    sess.graph.get_tensor_by_name('detection_scores:0'),\n",
    "                    sess.graph.get_tensor_by_name('detection_boxes:0'),\n",
    "                    sess.graph.get_tensor_by_name('detection_classes:0')],\n",
    "                   feed_dict={'image_tensor:0': inp.reshape(1, inp.shape[0], inp.shape[1], 3)})\n",
    "    \n",
    "    num_detections = int(out[0][0])\n",
    "    \n",
    "    for i in range(num_detections):\n",
    "        classId = int(out[3][0][i])\n",
    "        score = float(out[1][0][i])\n",
    "        bbox = [float(v) for v in out[2][0][i]]\n",
    "    \n",
    "        if score > 0.3:\n",
    "            x = bbox[1] * cols\n",
    "            y = bbox[0] * rows\n",
    "            right = bbox[3] * cols\n",
    "            bottom = bbox[2] * rows\n",
    "            cv.rectangle(img, (int(x), int(y)), (int(right), int(bottom)), (0, 0, 0), thickness=2)\n",
    "            ##print((int(x), int(y)))  top left coordinate\n",
    "            ##print((int(right), int(bottom))) bottom right coordinate\n",
    "            print(label[classId-1])\n",
    "            points = get_points(int(x), int(y), int(right), int(bottom))\n",
    "            print(final_depth(points))\n",
    "\n",
    "            \n",
    "cv.imshow('Image', img)\n",
    "cv.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
